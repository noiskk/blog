---
layout: post
title: "[ML] Logistic Regression"
date: 2024-09-29 12:00:00 +0900
categories: Machine_Learning
use_math: true
---

### **Logistic Regression(로지스틱 회귀)**
**이진 분류** 문제를 해결하는 데 주로 사용되는 통계적 모델<br> 목표 변수(출력)가 **카테고리형**일 때, 즉 결과가 두 가지 클래스 중 하나인 경우에 사용된다. <br>비록 'Regression(회귀)'라는 이름을 가지고 있지만, 실제로는 **Classification(분류)** 알고리즘이다.

### Logistic Regression의 작동 방식

Logistic Regression 는 특정 데이터 포인트가 특정 클래스에 속할 **확률**을 예측합니다. 이 확률은 **sigmoid function(시그모이드 함수)**를 사용하여 계산되며, 이 함수는 입력을 0과 1 사이의 값으로 매핑한다.

#### 1. **선형 모델**:
   먼저 입력 특성들의 **선형 결합**을 계산합니다. 이 과정은 선형 회귀와 유사하다 
   
   $z = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_n x_n$
   - $z$: 입력 특성들의 선형 결합,
   - $\beta_0$: 절편(편향),
   - $\beta_1, \dots, \beta_n$: 각 특성에 대한 계수(가중치),
   - $x_1, \dots, x_n$: 각 특성의 값입니다.

#### 2. **sigmoid function**:
   선형 결합 $z$ 값을 **sigmoid function**에 통과시켜 0과 1 사이의 확률을 계산한다

   $\sigma(z) = \frac{1}{1 + e^{-z}}$

   sigmoid function 는 **S자 형태의 곡선**
   - $z$ 값이 **큰 양수**로 갈수록 출력값은 **1**에 가까워짐 (클래스 1).
   - $z$ 값이 **큰 음수**로 갈수록 출력값은 **0**에 가까워짐 (클래스 0).

   함수의 출력값은 클래스 1에 속할 확률을 의미하며, 보통 이 값이 **0.5 이상**이면 클래스 1, 그보다 낮으면 클래스 0으로 분류합니다.

#### 3. **Decision boundary결정 경계**:
   Logistic Regression 는 **선형 결정 경계(linear decision boundary)**를 사용한다. 즉, 두 클래스 간의 경계를 직선 또는 고차원 공간에서 **평면**으로 정의합니다. 분류는 결정 경계에 따라 이루어지며, 다음 조건에서 결정 경계가 형성된다:

   $\sigma(z) = 0.5 \quad \text{또는} \quad z = 0$

   이는 두 클래스가 동등한 확률을 가질 때이다.

### 목적 함수: 최대 우도 추정(Maximum Likelihood Estimation, MLE)

로지스틱 회귀 모델은 **최대 우도 추정(MLE)**을 사용하여 학습됩니다. 즉, 모델은 예측된 확률이 실제 라벨과 최대한 맞도록 계수를 조정합니다.

로지스틱 회귀에서의 **로그 우도 함수**는 다음과 같이 정의됩니다:

$L(\beta) = \sum_{i=1}^{n} \left[ y_i \log(\hat{p_i}) + (1 - y_i) \log(1 - \hat{p_i}) \right]$
- $y_i$: 데이터 포인트 $i$의 실제 라벨(0 또는 1),
- $\hat{p_i}$: 데이터 포인트 $i$에 대한 예측 확률입니다.

모델은 **경사 하강법(Gradient Descent)**과 같은 최적화 기법을 통해 로그 우도를 최대화하는 방향으로 학습합니다.

### Logistic Regression 종류

1. **이진 로지스틱 회귀**: 출력이 두 개의 클래스(예: "스팸/스팸 아님")인 경우 사용됩니다.
   
2. **다항 로지스틱 회귀(Multinomial Logistic Regression)**: 여러 클래스(예: "고양이/강아지/토끼")가 있을 때 사용되는 확장 기법으로, **소프트맥스(Softmax)** 함수를 사용해 각 클래스에 속할 확률을 예측합니다.

3. **순서형 로지스틱 회귀(Ordinal Logistic Regression)**: 라벨이 **순서**가 있는 경우 (예: "낮음/보통/높음")에 사용됩니다.

### Logistic Regression와 Linear Regression 의 차이

- **목적**: 선형 회귀는 **연속적인 값**을 예측하는 반면, 로지스틱 회귀는 **카테고리(클래스)**를 예측하는 데 사용됩니다.
- **출력**: 선형 회귀는 **실수 값**을 출력하지만, 로지스틱 회귀는 **0과 1 사이의 확률**을 출력합니다.
- **모델링 함수**: 선형 회귀는 **직선**을 사용하고, 로지스틱 회귀는 **시그모이드 함수**를 사용하여 데이터를 모델링합니다.

### Linear Regression 장점

1. **간단하고 해석 가능**: 로지스틱 회귀는 간단하며, 각 특성의 가중치가 결과에 미치는 영향을 쉽게 해석할 수 있습니다.
2. **확률적 출력**: 예측 결과가 확률로 제공되므로 **결정 임계값**을 유연하게 조정할 수 있습니다.
3. **효율성**: 작은 데이터셋에서 빠르고 효과적으로 동작합니다.

### Linear Regression 단점

1. **선형 결정 경계**: 로지스틱 회귀는 **선형** 관계를 가정하기 때문에 비선형 데이터에서는 성능이 떨어질 수 있습니다.
2. **이상치에 민감**: 선형 회귀처럼, 로지스틱 회귀도 **이상치(outliers)**에 민감할 수 있습니다.
3. **이진 및 다항 분류에 제한**: 복잡한 계층적 클래스 문제나 불균형한 데이터셋에서는 성능이 떨어질 수 있습니다.

### Linear Regression 사용 사례

1. **이진 분류 문제**: 로지스틱 회귀는 이진 분류 문제에서 자주 사용됩니다. 예를 들면:
   - **이메일 스팸 분류**: 이메일이 스팸인지 아닌지 예측.
   - **고객 이탈 예측**: 고객이 서비스에서 이탈할지 예측.
   - **의료 진단**: 환자가 특정 질병에 걸릴 확률 예측.

2. **신용 점수 예측**: 대출 신청자가 대출을 상환할 확률을 예측합니다.
   
3. **마케팅**: 특정 제품을 구매할 확률을 예측하여 마케팅 전략에 활용됩니다.

### Linear Regression 정규화(Regularization)

**과적합(Overfitting)**을 방지하기 위해 **L2 정규화** (릿지, Ridge) 또는 **L1 정규화** (라쏘, Lasso)를 사용할 수 있습니다. 이는 손실 함수에 **패널티 항**을 추가하여, 모델이 너무 복잡해지지 않도록 제어합니다.


$\text{L2 패널티: } \frac{\lambda}{2} \sum_{j=1}^{n} \beta_j^2$

여기서 $\lambda$는 정규화 강도를 조절하는 하이퍼파라미터입니다.

